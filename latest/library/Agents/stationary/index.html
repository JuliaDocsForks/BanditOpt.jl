<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Stationary Bandit Agents · BanditOpt.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link href="../../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>BanditOpt.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../../">Home</a></li><li><a class="toctext" href="../../../start/">Getting Started</a></li><li><a class="toctext" href="../../../concepts/">Concepts</a></li><li><span class="toctext">Library</span><ul><li><span class="toctext">Agents</span><ul><li><a class="toctext" href="../">Agents</a></li><li class="current"><a class="toctext" href>Stationary Bandit Agents</a><ul class="internal"><li><a class="toctext" href="#ϵ-Greedy-Agent-1">ϵ-Greedy Agent</a></li><li><a class="toctext" href="#ϵₙ-Greedy-Agent-1">ϵₙ-Greedy Agent</a></li></ul></li><li><a class="toctext" href="../nonstationary/">Nonstationary Bandit  Agents</a></li></ul></li><li><span class="toctext">Arms</span><ul><li><a class="toctext" href="../../Arms/">Arms</a></li><li><a class="toctext" href="../../Arms/stationary/">Stationary Arm Models</a></li><li><a class="toctext" href="../../Arms/nonstationary/">Non-stationary Arm Models</a></li></ul></li></ul></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="../../../contributing/">-</a></li><li><a class="toctext" href="../../../ack/">-</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Library</li><li>Agents</li><li><a href>Stationary Bandit Agents</a></li></ul><a class="edit-page" href="https://github.com/v-i-s-h/BanditOpt.jl/blob/master/docs/src/library/Agents/stationary.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Stationary Bandit Agents</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Stationary-Bandit-Agents-1" href="#Stationary-Bandit-Agents-1">Stationary Bandit Agents</a></h1><p>This page lists stationary bandit agents available in the package.</p><h2><a class="nav-anchor" id="ϵ-Greedy-Agent-1" href="#ϵ-Greedy-Agent-1">ϵ-Greedy Agent</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BanditOpt.Agents.epsGreedy" href="#BanditOpt.Agents.epsGreedy"><code>BanditOpt.Agents.epsGreedy</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">epsGreedy( noOfArms, ϵ )</code></pre><p>Implements constant exploration ϵ-greedy agent. <code>noOfArms</code> is the number of arms to pick from and <code>ϵ</code> is the exploration factor.</p></div></div><a class="source-link" target="_blank" href="https://github.com/v-i-s-h/BanditOpt.jl/blob/ee421a78dcbb72bc37021dffb9c393e5b43fec9a/src/Agents/EpsilonGreedy.jl#L1-L5">source</a></section><h2><a class="nav-anchor" id="ϵₙ-Greedy-Agent-1" href="#ϵₙ-Greedy-Agent-1">ϵₙ-Greedy Agent</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="BanditOpt.Agents.epsNGreedy" href="#BanditOpt.Agents.epsNGreedy"><code>BanditOpt.Agents.epsNGreedy</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">epsNGreedy( noOfArms, c , d )</code></pre><p>Implementats decaying exploration factor ϵ-greedy agent. <code>noOfArms</code> is the number of of options, <code>c</code> and <code>d</code> are algorithm dependent parameters.</p><p>Reference: Auer, P., Bianchi, N. C., &amp; Fischer, P. (2002). Finite time analysis of the multiarmed bandit problem. Machine Learning, 47, 235–256.</p></div></div><a class="source-link" target="_blank" href="https://github.com/v-i-s-h/BanditOpt.jl/blob/ee421a78dcbb72bc37021dffb9c393e5b43fec9a/src/Agents/EpsilonGreedy.jl#L68-L74">source</a></section><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Agents</span></a><a class="next" href="../nonstationary/"><span class="direction">Next</span><span class="title">Nonstationary Bandit  Agents</span></a></footer></article></body></html>
